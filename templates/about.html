<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About - Text-to-Speech Buddy</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">
</head>
<body>
    <div class="container">
        <header>
            <h1>üìñ About This Project</h1>
            <p class="subtitle">Neural Text-to-Speech for Digital Accessibility</p>
        </header>

        <main>
            <section class="about-section">
                <h2>üéØ Project Overview</h2>
                <p>
                    This Text-to-Speech Accessibility Platform is an AI-powered web application 
                    designed to make digital content accessible to everyone. Built as part of an 
                    artificial intelligence course project, it demonstrates practical applications 
                    of deep learning for social good.
                </p>
            </section>

            <section class="about-section">
                <h2>ü§ñ Technology Stack</h2>
                <div class="tech-list">
                    <div class="tech-item">
                        <strong>Frontend:</strong> HTML5, CSS3, JavaScript
                    </div>
                    <div class="tech-item">
                        <strong>Backend:</strong> Flask (Python)
                    </div>
                    <div class="tech-item">
                        <strong>AI Model:</strong> Bark by Suno AI (Transformer-based TTS)
                    </div>
                    <div class="tech-item">
                        <strong>Framework:</strong> PyTorch, Hugging Face Transformers
                    </div>
                </div>
            </section>

            <section class="about-section">
                <h2>üß† AI Methods Used</h2>
                <ul>
                    <li><strong>Deep Neural Networks:</strong> Transformer architecture for sequence modeling</li>
                    <li><strong>Attention Mechanisms:</strong> Self-attention for text-to-audio alignment</li>
                    <li><strong>Transfer Learning:</strong> Pre-trained models from Hugging Face</li>
                    <li><strong>Generative AI:</strong> Neural vocoding for audio synthesis</li>
                </ul>
            </section>

            <section class="about-section">
                <h2>üéì Educational Goals</h2>
                <p>This project demonstrates:</p>
                <ul>
                    <li>Practical implementation of AI principles and algorithms</li>
                    <li>Data-driven reasoning and decision-making</li>
                    <li>Real-world applications of machine learning</li>
                    <li>Ethical considerations in AI development</li>
                    <li>Full-stack development with AI integration</li>
                </ul>
            </section>

            <section class="about-section">
                <h2>‚ôø Accessibility Features</h2>
                <ul>
                    <li>WCAG 2.1 Level AA compliant interface</li>
                    <li>Keyboard navigation support</li>
                    <li>Screen reader compatible</li>
                    <li>High contrast color scheme</li>
                    <li>Responsive design for all devices</li>
                </ul>
            </section>

            <section class="about-section">
                <h2>‚öñÔ∏è Ethical Considerations</h2>
                <p>We acknowledge the following ethical considerations:</p>
                <ul>
                    <li><strong>Deepfake Risks:</strong> Technology could be misused for voice impersonation</li>
                    <li><strong>Bias:</strong> Training data may contain accent and pronunciation biases</li>
                    <li><strong>Privacy:</strong> No user data is stored or transmitted</li>
                    <li><strong>Accessibility:</strong> Tool augments but doesn't replace human interaction</li>
                    <li><strong>Environmental Impact:</strong> AI models consume computational resources</li>
                </ul>
            </section>

            <section class="about-section">
                <h2>üöÄ Future Enhancements</h2>
                <ul>
                    <li>OCR integration for image-to-speech conversion</li>
                    <li>Multi-language support</li>
                    <li>Custom voice training</li>
                    <li>PDF and document upload support</li>
                    <li>User accounts and history</li>
                    <li>Mobile application</li>
                </ul>
            </section>

            <section class="about-section">
                <h2>üë• Team</h2>
                <p>
                    This project was developed as part of an AI course project at [Your University]. 
                    Team members: [Add your names here]
                </p>
            </section>

            <section class="about-section">
                <h2>üìö References</h2>
                <ol>
                    <li>Kim, J., et al. (2021). "Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech." ICML 2021.</li>
                    <li>Suno AI (2023). Bark: Text-Prompted Generative Audio Model.</li>
                    <li>Vaswani, A., et al. (2017). "Attention Is All You Need." NeurIPS 2017.</li>
                    <li>W3C Web Accessibility Initiative. WCAG 2.1 Guidelines.</li>
                </ol>
            </section>

            <div class="back-link">
                <a href="/" class="btn btn-primary">‚Üê Back to Home</a>
            </div>
        </main>

        <footer>
            <p>Built with ‚ù§Ô∏è for accessibility | Using Bark TTS Model</p>
        </footer>
    </div>
</body>
</html>